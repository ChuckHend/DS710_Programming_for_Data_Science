{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1(a).  Word length.\n",
    "\n",
    "Write a function called ```word_length_list()``` which takes a string and returns a list with the length of each word in the string.  For each word, count the number of English, alphanumeric characters.  Words are defined as text separated by spaces. Your function should ignore punctuation.  For example, ```word_length_list(\"Haven't you eaten 8 oranges today?\")``` should return ```[6,3,5,1,7,5]```.  \n",
    "\n",
    "* Call or create other functions as necessary to organize your work.\n",
    "* Do *not* use Python packages (like nltk) or code directly copied from online resources (such as regular expressions for splitting text) in order to divide sentences. Write your own code to do this from first principles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test=\"Haven't you eaten 8 oranges today?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to drop the punctuations from the string\n",
    "def drop_pun(str_var):\n",
    "    ignore='!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "    str_cln=str_var.translate({ord(x): '' for x in ignore})\n",
    "    return str_cln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_length_list(str_arg):\n",
    "    # call the drop punctuation function\n",
    "    cleaned=drop_pun(str_arg)\n",
    "    # split string to seprate words by space\n",
    "    str_split=cleaned.split()\n",
    "    # apply len function to leach element in str_split\n",
    "    lengths=list(map(len, str_split))\n",
    "    return lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 3, 5, 1, 7, 5]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call the function\n",
    "word_length_list(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1(b).  \"A Mourner.\"\n",
    "\n",
    "The text below is an anonymous essay published in The Boston Gazette and Country Journal on January 8, 1770. \n",
    "\n",
    ">The general Sympathy and Concern for the Murder of the Lad by the base and infamous Richardson on the 22d Instant, will be sufficient Reason for your Notifying the Public that he will be buried from his Father’s House in Frogg Lane, opposite Liberty-Tree, on Monday next, when all the Friends of Liberty may have an Opportunity of paying their last Respects to the Remains of this little Hero and first Martyr to the noble Cause--Whose manly Spirit (after this Accident happened) appear’d in his discreet Answers to his Doctor, his Thanks to the Clergymen who prayed with him, and Parents, and while he underwent the greatest Distress of bodily Pain; and with which he met the King of Terrors.  These Things, together with the several heroic Pieces found in his Pocket, particularly Wolfe’s Summit of human Glory, gives Reason to think he had a martial Genius, and would have made a clever Man.\n",
    "\t\t\t\t\t\n",
    "> A Mourner.\n",
    "\n",
    "(Source:  Michael Sullivan, _Statistics:  Informed Decisions Using Data_, 4th ed.  p. 188-189.)\n",
    "\n",
    "Use your function ```word_length_list()``` from 1(a) to find the length of each word in \"A Mourner\". (Note that your output should end in . . ., 3, 1, 7].)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mourner='The general Sympathy and Concern for the Murder of the Lad by the base and infamous Richardson on the \\\n",
    "        22d Instant, will be sufficient Reason for your Notifying the Public that he will be buried from his Father’s\\\n",
    "        House in Frogg Lane, opposite Liberty-Tree, on Monday next, when all the Friends of Liberty may have an \\\n",
    "        Opportunity of paying their last Respects to the Remains of this little Hero and first Martyr to the noble\\\n",
    "        Cause--Whose manly Spirit (after this Accident happened) appear’d in his discreet Answers to his Doctor, his\\\n",
    "        Thanks to the Clergymen who prayed with him, and Parents, and while he underwent the greatest Distress of \\\n",
    "        bodily Pain; and with which he met the King of Terrors. These Things, together with the several heroic Pieces\\\n",
    "        found in his Pocket, particularly Wolfe’s Summit of human Glory, gives Reason to think he had a martial\\\n",
    "        Genius, and would have made a clever Man. \\\n",
    "        A Mourner.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 7, 8, 3, 7, 3, 3, 6, 2, 3, 3, 2, 3, 4, 3, 8, 10, 2, 3, 3, 7, 4, 2, 10, 6, 3, 4, 9, 3, 6, 4, 2, 4, 2, 6, 4, 3, 8, 5, 2, 5, 4, 8, 11, 2, 6, 4, 4, 3, 3, 7, 2, 7, 3, 4, 2, 11, 2, 6, 5, 4, 8, 2, 3, 7, 2, 4, 6, 4, 3, 5, 6, 2, 3, 5, 10, 5, 6, 5, 4, 8, 8, 8, 2, 3, 8, 7, 2, 3, 6, 3, 6, 2, 3, 9, 3, 6, 4, 3, 3, 7, 3, 5, 2, 9, 3, 8, 8, 2, 6, 4, 3, 4, 5, 2, 3, 3, 4, 2, 7, 5, 6, 8, 4, 3, 7, 6, 6, 5, 2, 3, 6, 12, 7, 6, 2, 5, 5, 5, 6, 2, 5, 2, 3, 1, 7, 6, 3, 5, 4, 4, 1, 6, 3, 1, 7]\n"
     ]
    }
   ],
   "source": [
    "print(word_length_list(mourner))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1(c). _Pride and Prejudice_.\n",
    "\n",
    "Create a function to count the number of words and mean length of words in each sentence of Pride and Prejudice (We have provided a .txt file in the repo, which is available without restrictions from Project Gutenberg).  Save your result as a ```.csv``` file and include it with your submission.\n",
    "\n",
    "* Create additional functions as necessary to organize your work.\n",
    "* Include comments to explain the purpose and arguments of each function you create.\n",
    "* Note that the mean length of words in the sample sentence from 1(a) ```\"Haven't you eaten 8 oranges today?\"``` is 4.5.\n",
    "* A sentence ends with a period, exclamation point, or question mark. A hyphen, dash, or apostrophe does not end a sentence. Quotation marks do not end a sentence. But also, some periods do not end sentences. For example, Mrs., Mr., Dr., Fr., Jr., St., are all commonly occurring abbreviations that almost never end sentences, and they occur enough in Pride and Prejudice that you need to deal with them or your averages will be impacted significantly. An ellipsis sometimes ends a sentence and sometimes does not, but for this assignment you may assume an ellipsis ends a sentence (but note it does not end 3 sentences!) \n",
    "* Do *not* use Python packages (like nltk) or code directly copied from online resources (such as regular expressions for splitting text) in order to divide sentences. Write your own code to do this from first principles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove some encoding junk\n",
    "# takes in a text string(use entire text for this project)\n",
    "def clean_encoding(string_var):\n",
    "    junk=['\\x94', '\\x93', '\\x92', '\\x91']\n",
    "    cleaned=string_var.translate({ord(x): '' for x in junk})\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to match the salutation string\n",
    "# determine if a string contains the following salutations\n",
    "# removes the period if there is a match\n",
    "def match_salute(string_var):\n",
    "    salutes = ['Mrs.', 'Mr.', 'Dr.', 'Fr.', 'Jr.', 'St.']\n",
    "    if string_var in salutes:\n",
    "        return string_var.strip('.')\n",
    "    else:\n",
    "        return string_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to drop the periods after salutations\n",
    "# uses match_salute function to do the actual dropping of the period\n",
    "def process_salutes(string_var):\n",
    "    string_var=string_var.split()\n",
    "    string_var=list(map(lambda x: match_salute(x), string_var))\n",
    "    string_var=' '.join(string_var)\n",
    "    return string_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop sentence ending special characters\n",
    "# remove all the special characters from the text\n",
    "# but not things that might be end of sentence punctuations\n",
    "def drop_char(string_var):\n",
    "    dropChar='\"#$%&\\'()*+,-/:;<=>@[\\\\]^_`{|}~'\n",
    "    string_var= ''.join(string_var)\n",
    "    string_cln=string_var.translate({ord(x): '' for x in dropChar})\n",
    "    return string_cln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to split the entire book down into a list of sentences\n",
    "# takes in a giant string, converts ! and ? to '.', then splits string based on '.'\n",
    "def create_sentences(book):\n",
    "    replace_list=['!', '?']\n",
    "    for pun in replace_list:\n",
    "        book=book.replace(pun, '.')\n",
    "    sentences=book.split('.')\n",
    "    # finally, drop all punctuations\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# produce summary statistics on the list of sentences\n",
    "# taken in a list of sentences\n",
    "# outputs number of words and mean word length for each sentence\n",
    "def summary_words(sentences):\n",
    "    import pandas as pd\n",
    "    # get the number of characters in each sentence, save it as a list\n",
    "    chars=list(map(lambda x: len(x.replace(' ', '')), sentences))\n",
    "    # split each sentence to a list of words and get the length of words in the liust\n",
    "    nwords =list(map(lambda x: len(x.split()), sentences))\n",
    "    df= pd.DataFrame({'Words': nwords,\n",
    "                      'Chars': chars})\n",
    "    df=df.loc[~(df==0).all(axis=1)] # drop sentences with 0 length\n",
    "    df['MeanWordLen']=df.Chars/df.Words\n",
    "    df.drop('Chars', axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# returns two list\n",
    "# number of words in each sentence, \n",
    "#  and number of characters in each sentence\n",
    "def word_analysis(book):\n",
    "    cln=clean_encoding(book)\n",
    "    cln=drop_char(cln)\n",
    "    cln=process_salutes(cln)\n",
    "    cln=create_sentences(cln)\n",
    "    summary=summary_words(cln)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in file\n",
    "with open('pride.txt', 'r',encoding=\"latin-1\") as file:\n",
    "    pride=file.read().replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conduct the analysis on the data file\n",
    "summary=word_analysis(pride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>MeanWordLen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>4.161290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>4.425532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>3.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>3.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>3.421053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Words  MeanWordLen\n",
       "0     31     4.161290\n",
       "1     47     4.425532\n",
       "2     21     3.714286\n",
       "3      7     3.857143\n",
       "4     19     3.421053"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the results\n",
    "import pandas as pd\n",
    "summary.to_csv('pride_pred_results.csv', index=False)\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 Introduction.  Counting the Letter _e_.\n",
    "\n",
    "Here we will be counting e's in text files, capitalized and uncapitalized, and accented and unaccented.\n",
    "\n",
    "* Your code in 2(b) should include a function called ```count_letter_e()``` which takes a string representing a filename, such as ```pg1342.txt```, as input, and returns the number of _e_'s as output.  Your function should include two optional arguments, ```ignore_accents``` and ```ignore_case```.  When ```ignore_accents = True```, your function should count accented characters such as _é_, _ê_, and _è_ as the same as _e_.  When ```ignore_case=True```, your function should treat uppercase and lowercase _e_ as the same letter.\n",
    "* The function ```count_letter_e()``` should return a *single number*, the total number of all characters that are being treated as equivalent to _e_.\n",
    "* Create other functions as necessary to organize your work.\n",
    "* Include comments which explain the purpose and arguments of each function you create.\n",
    "* The files are encoded as utf-8. Unrecognized character error messages can likely be fixed by specifying the encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Problem 2(a).  Design a Test Suite.\n",
    "\n",
    "Design a test suite (which will be in this case a set of input text) of at least four sentences that will allow you to quickly verify that all four optional argument possibilities are implemented correctly. Make sure that your test suite contains at least one of each of the 8 possible e's (e, é, ê, è, E, É, Ê, È).\n",
    "\n",
    "Save your test suite as a set of text files (1 sentence per text file) for use in your ```count_letter_e()``` function, and also include each test sentence in a different markdown cell below. For each sentence, count each type of e by hand and report (in the markdown cell) what the output should be for the four possible combinations of true and false for ```ignore_case``` and ```ignore_accents```.\n",
    "\n",
    "*Note that you can complete this portion before you have written a single line of code for your function ```count_letter_e()```.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test sentence 1:\n",
    "\n",
    "'The quick brown fox jumped over the lazy dogs'\n",
    "* ignore_case=True, ignore_accents=True: 4\n",
    "* ignore_case=True, ignore_accents=False: 4\n",
    "* ignore_case=False, ignore_accents=False: 4\n",
    "* ignore_case=False, ignore_accents=True: 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test sentence 2:\n",
    "\n",
    "'The letters e, é, ê, è, E, É, Ê, È are important to distinguish from one another'\n",
    "* ignore_case=True, ignore_accents=True: 14\n",
    "* ignore_case=True, ignore_accents=False: 8\n",
    "* ignore_case=False, ignore_accents=False: 7\n",
    "* ignore_case=False, ignore_accents=True: 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test sentence 3:\n",
    "\n",
    "'See you at the storé'\n",
    "* ignore_case=True, ignore_accents=True: 4\n",
    "* ignore_case=True, ignore_accents=False: 3\n",
    "* ignore_case=False, ignore_accents=False: 3\n",
    "* ignore_case=False, ignore_accents=True: 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test sentence 4:\n",
    "\n",
    "'No charact3r in this t3st cas3'\n",
    "* ignore_case=True, ignore_accents=True: 0\n",
    "* ignore_case=True, ignore_accents=False: 0\n",
    "* ignore_case=False, ignore_accents=False: 0\n",
    "* ignore_case=False, ignore_accents=True: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a list of test sentences\n",
    "t1='The quick brown fox jumped over the lazy dogs'\n",
    "t2='The letters e, é, ê, è, E, É, Ê, È are important to distinguish from one another'\n",
    "t3='See you at the storê'\n",
    "t4='No charact3r in this t3st cas3'\n",
    "t=[t1]+[t2]+[t3]+[t4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to save sentences to txt files\n",
    "def save_texts(text_lists):\n",
    "    for i, sentence in enumerate(text_lists):\n",
    "        text_file = open('test_{}.txt'.format(str(i+1)), \"w\")\n",
    "        text_file.write(sentence)\n",
    "        text_file.close()\n",
    "        print('File {} Saved...'.format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 1 Saved...\n",
      "File 2 Saved...\n",
      "File 3 Saved...\n",
      "File 4 Saved...\n"
     ]
    }
   ],
   "source": [
    "# save all the test sentences to file\n",
    "save_texts(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2(b). Create and Test Your Code.\n",
    "\n",
    "Create the functions described in Problem 2 Introduction, and apply them to your test suite from 2(a).  Do *not* use Python packages or code directly copied from online resources.  Write your own functions from first principles.\n",
    "\n",
    "Print the results of applying the four combinations of optional arguments of your ```count_letter_e()``` function to your test suite. Verify that the output is correct. (If it isn't, modify your code until your function works correctly on your test suite.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname_ext=\"test_1.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# come up with the our list of the letter e that we want to count on\n",
    "# only depends on arguments to ignore accents or ignore case\n",
    "# we are predetermining which letter we want to search for based on \n",
    "# the parameters ignore_accents and ignore_case\n",
    "def make_e_list(ignore_accents=True, ignore_case=True):\n",
    "    eList=['e', 'é', 'ê', 'è', 'E', 'É', 'Ê', 'È']\n",
    "    if not ignore_accents:\n",
    "        dropList=['é', 'ê', 'è','É', 'Ê', 'È']\n",
    "        eList=[x for x in eList if x not in dropList]\n",
    "    if not ignore_case:\n",
    "        dropList=['E', 'É', 'Ê', 'È']\n",
    "        eList=[x for x in eList if x not in dropList]\n",
    "    return eList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# takes a list of the filenames.ext to test on\n",
    "# makes a list of the text contained in files\n",
    "def read_tests(test_list):\n",
    "    test_sentences=[]\n",
    "    for file in test_list:\n",
    "        f = open(file, 'r') \n",
    "        test_sentences.append(f)\n",
    "    return test_sentences\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count the number of times the words in our list are found in the text\n",
    "def count_letter_e(fname_ext, ignore_case=True, ignore_accents=True, ):\n",
    "    file = open(fname_ext, 'r')\n",
    "    file=file.read()\n",
    "    eList=make_e_list(ignore_accents, ignore_case)\n",
    "    #print(eList)\n",
    "    count=0\n",
    "    for char in eList:\n",
    "        count+=file.count(char)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a list of the files with test sentences in them\n",
    "test_files=['test_1.txt', 'test_2.txt', 'test_3.txt', 'test_4.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function that will test all four combinations of ignore_case and ignore_accents\n",
    "# a list of file names that we pass to it\n",
    "def all_tests(test_files):\n",
    "    print('ignore_case/ignore_accents')\n",
    "    for file in test_files:\n",
    "        print(file)\n",
    "        print('T/T', count_letter_e(file, ignore_case=True, ignore_accents=True))\n",
    "        print('T/F', count_letter_e(file, ignore_case=True, ignore_accents=False))\n",
    "        print('F/F', count_letter_e(file, ignore_case=False, ignore_accents=False))\n",
    "        print('T/F', count_letter_e(file, ignore_case=False, ignore_accents=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ignore_case/ignore_accents\n",
      "test_1.txt\n",
      "T/T 4\n",
      "T/F 4\n",
      "F/F 4\n",
      "T/F 4\n",
      "test_2.txt\n",
      "T/T 14\n",
      "T/F 8\n",
      "F/F 7\n",
      "T/F 10\n",
      "test_3.txt\n",
      "T/T 4\n",
      "T/F 3\n",
      "F/F 3\n",
      "T/F 4\n",
      "test_4.txt\n",
      "T/T 0\n",
      "T/F 0\n",
      "F/F 0\n",
      "T/F 0\n"
     ]
    }
   ],
   "source": [
    "# run the test on all our test files\n",
    "all_tests(test_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2(c). Apply Your Code.\n",
    "\n",
    "Apply your code from 2(b) to the two provided .txt files for _Pride and Prejudice_  and _L'Enlèvement de la redoute_. For each file, print the output of all four combinations of arguments to your count_letter_e function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a list of the two files we want to read in\n",
    "trialList = ['pride.txt', \"l'enlevement.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ignore_case/ignore_accents\n",
      "pride.txt\n",
      "T/T 69372\n",
      "T/F 69372\n",
      "F/F 68641\n",
      "T/F 68641\n",
      "l'enlevement.txt\n",
      "T/T 1486\n",
      "T/F 1289\n",
      "F/F 1273\n",
      "T/F 1469\n"
     ]
    }
   ],
   "source": [
    "# run the same test on each of these files\n",
    "all_tests(trialList)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
